{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 एक\n",
      "2 इस\n",
      "2 उन\n",
      "4 बाबू\n",
      "5 प्रेस\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "\n",
    "files = [\"bhairav\", \"dharamveer\", \"premchand\", \"sharatchandra\", \"vibhooti\"]\n",
    "n = 1\n",
    "\n",
    "piece_ngram_frequency = []\n",
    "piece_author = []\n",
    "\n",
    "for file_name in files:\n",
    "    pickle_file = open(\"../pickles/author_splits/\" + file_name + \".pkl\" , \"rb\")\n",
    "    split_text = pickle.load(pickle_file)\n",
    "    pickle_file.close()\n",
    "    \n",
    "    for text in split_text:\n",
    "        text = text.replace('।','')\n",
    "        text = text.replace('.','')\n",
    "        text = text.replace(',','')\n",
    "        text = text.replace(':','')\n",
    "        text = text.replace(';','')\n",
    "        text = text.replace('?','')\n",
    "        text = text.replace('!','')\n",
    "        text = text.replace('-','')\n",
    "        text = text.replace(\"’\",\"\")\n",
    "        text = text.replace(\"''\",\"\")\n",
    "        text = text.replace('\"','')\n",
    "        \n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        grams = nltk.ngrams(tokens, n)\n",
    "        piece_ngram_frequency.append(dict(nltk.FreqDist(grams)))\n",
    "        piece_author.append(file_name)\n",
    "        \n",
    "corpus_ngram_frequency = {}\n",
    "\n",
    "for ngf in piece_ngram_frequency:\n",
    "    for ng in ngf.keys():\n",
    "        if ng not in corpus_ngram_frequency:\n",
    "            corpus_ngram_frequency[ng] = 0\n",
    "        corpus_ngram_frequency[ng] += ngf[ng]\n",
    "\n",
    "corpus_ngram_frequency = dict(sorted(corpus_ngram_frequency.items(), key=lambda x:x[1], reverse=True)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_frequencies = []\n",
    "\n",
    "for ngf in piece_ngram_frequency:\n",
    "    ng_freq_list = []\n",
    "    for ng in corpus_ngram_frequency.keys():\n",
    "        if ng in ngf:\n",
    "            ng_freq_list.append(ngf[ng])\n",
    "        else:\n",
    "            ng_freq_list.append(0)\n",
    "    piece_frequencies.append(ng_freq_list)\n",
    "\n",
    "feature_vector = [piece_author, piece_frequencies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open(\"../pickles/feature_vectors/n_grams/\" + str(n) + \"grams.pkl\" , \"wb\")\n",
    "pickle.dump(feature_vector, pickle_file)\n",
    "pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
